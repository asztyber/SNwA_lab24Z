{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c172ad-fcf5-4a9b-95a0-edcc33dbc20e",
   "metadata": {},
   "source": [
    "# Lab 5 Sieci Neuronowe w Automatyce -  Q-learning\n",
    "\n",
    "Celem ćwiczenia jest implementacja algorytmu DQN, który nauczy się sterować odwróconym wahadłem utrzymując je w górze.\n",
    "\n",
    "Punktacja: \n",
    "* 8 pkt. działający kod (wahadło utrzymane w górze powyżej 200 kroków)\n",
    "* 2 pkt. odpowiedzi na pytania\n",
    "\n",
    "Imię i nazwisko: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8df9b-b34a-4386-96d5-9ca3cf5565a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doinstalowujemy potrzebne biblioteki\n",
    "!pip install gymnasium imageio ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660f74c1-d35e-49ba-8f95-65fb76b9f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy.testing as npt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb5054d-d263-4358-ba3b-d189b635b00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01899745 -0.01913439 -0.03491143 -0.01571686]\n"
     ]
    }
   ],
   "source": [
    "# tworzymy środowisko\n",
    "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")\n",
    "observation, _ = env.reset()\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c7721-46cf-48c6-a118-4df9c4deb099",
   "metadata": {},
   "source": [
    "#### Obserwacje (stan)\n",
    "Obserwacje to:\n",
    "- $x$ - pozycja wózka\n",
    "- $\\dot{x}$ - prędkość wózka\n",
    "- $\\theta$ - kąt nachylenia wahadła\n",
    "- $\\dot{\\theta}$ - prędkość kątowa wahadła"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "768df5a1-266a-4459-af97-79914c00f694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac98d7f8-7058-49cd-a614-7bca0b3b6382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a0e0b7-561c-44df-8c99-c7816f05f083",
   "metadata": {},
   "source": [
    "#### Akcje\n",
    "Mamy dwie możliwe akcje:\n",
    "* 0 - przesuń wózek w lewo\n",
    "* 1 - przesuń wózek w prawo\n",
    "\n",
    "#### Nagrody\n",
    "Za każdy krok, póki wahadło nie spadnie, dostajemy nagrodę 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487680d-149e-43d0-8f5b-f73fad41e5df",
   "metadata": {},
   "source": [
    "### 1. Losowy agent\n",
    "Zaimplementować agenta wykonującego losowe akcje. Uruchomić 5 epizodów. Dla każdego epizodu policzyć skumuowane nagrody i wyświetlić. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f27affe3-9986-4c3a-a9ee-e42b3b2c04eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1315317361.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    action = #TODO wybrać losową akcję\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "rewards_list = []\n",
    "for i in range(5):\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    rewards = 0\n",
    "    while not done:\n",
    "        action = #TODO wybrać losową akcję\n",
    "        observation, reward, terminated, truncated, info = #TODO wykonać akcję\n",
    "        done = terminated or truncated\n",
    "        #TODO: dodać otrzymaną nagrodę do skumulowanej angrody\n",
    "    env.close()\n",
    "    #TODO: dodać skumulowane nagrody do listy nagród"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ce5499-dd56-4e54-9a36-c416e4805ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.0, 23.0, 17.0, 70.0, 31.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1234a94-1791-4ed9-a2b7-44a8da335c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy środowisko i ustawiamy maksymalną liczbę kroków\n",
    "max_steps = 300\n",
    "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1108c04-8663-43dd-b0be-b7fca4247673",
   "metadata": {},
   "source": [
    "#### Parametry\n",
    "* state_size - rozmiar przestrzeni stanu środowiska\n",
    "* buffer_size - rozmiar bufora\n",
    "* epsilon - początkowa wartość $\\epsilon$ do stosowania polityki $\\epsilon$ zachłannej\n",
    "* epsilon_decay - liczba przez którą mnożymy epsilon po każdym epizodzie\n",
    "* epsilon_min - ale epsilon nie powinien spadać poniżej epsilon_min\n",
    "* gamma - współczynnik dyskontujący\n",
    "* batch_size - rozmiar batcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94542ebe-efdd-4fc1-9472-b36103cf6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 4\n",
    "epsilon = 1\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.99\n",
    "gamma = 0.95\n",
    "batch_size = 32\n",
    "buffer_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f8422-e476-4afc-ae04-7ae4a268130e",
   "metadata": {},
   "source": [
    "#### 2. Tworzenie DQN\n",
    "Zaimplementuj funkcję tworzącą sieć aproksymującą Q - wartości. Zastosuj:\n",
    "* Dwie warstwy ukryte o 32 neuronach i funkcji aktywacji relu\n",
    "* Liniową funkcję aktywacji w warstwie wyjściowej\n",
    "* Optymalizator Adam i błąd średniokwadratowy jako funkcję straty\n",
    "* Liczba wejść sieci odpowiada rozmiarowi stanu środowiska\n",
    "* Liczba wyjść sieci odpowiada liczbie akcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8e04ad-af32-4eec-9cb8-fec89766aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_network():\n",
    "    model = tf.keras.Sequential()\n",
    "    #TODO dodać do sieci warstwy\n",
    "    model.compile(#TODO parametry)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee22c766-eb93-40e5-afb8-2835afd5ccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00020851 -0.00032942]]\n"
     ]
    }
   ],
   "source": [
    "model = make_network()\n",
    "state = np.array([[-0.005, 0.001, 0.0001, 0.0001]])\n",
    "q_values = model.predict(state, verbose=0)\n",
    "print(q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60d3eeb4-7ea8-4a05-99d4-f368cb740a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(q_values.shape == (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444d57dd-b43a-47e7-b11d-f3e66b88aa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wskazówka do 3\n",
    "q_values.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e3ed3f-9d2e-4740-b9c8-c2dfcd0c09f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m weight_sizes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m32\u001b[39m), (\u001b[38;5;241m32\u001b[39m,), (\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m), (\u001b[38;5;241m32\u001b[39m,), (\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m2\u001b[39m), (\u001b[38;5;241m2\u001b[39m,)]\n\u001b[0;32m      4\u001b[0m new_weights \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(size\u001b[38;5;241m=\u001b[39msize) \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m weight_sizes]\n\u001b[1;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mset_weights(new_weights)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# podmiana wag na konkretne wartości - tylko w celu testu poprawności implementacji w assercie poniżej\n",
    "np.random.seed(0)\n",
    "weight_sizes = [(4, 32), (32,), (32, 32), (32,), (32, 2), (2,)]\n",
    "new_weights = [np.random.normal(size=size) for size in weight_sizes]\n",
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e46377-794b-44f1-9e7a-543e31c576d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt.assert_allclose(model.predict(state, verbose=0), np.array([[-3.4027915, -6.6636534]]),\n",
    "                    rtol=1e-5, atol=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6fdf58-2dfd-42e7-82ef-142d35ca4ee7",
   "metadata": {},
   "source": [
    "#### 3. Wybór akcji\n",
    "Zaimplementuj funkcję get_action, realizującą strategię epsilon-zachłanną, która z prawdopodopieństwem epsilon wybiera losową akcję, a z prawdopodobieństwem 1 - epsilon akcję o największej Q-wartości dla danego stanu \n",
    "* Do losowania wykorzystać funkcję np.random.uniform()\n",
    "* Do wyboru akcji wywołać predykcję sieci dla danego stanu (model.predict(...)) i wykorzystać funkcję argmax\n",
    "* W funkcji predict zastosować argument verbose=0, który spowoduje, że nie będzie wydruków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5481ae6e-486e-43b5-a993-e382a883f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(env, state, model, epsilon):\n",
    "    #TODO\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd26505-a25b-4e3d-87d6-b16044a6d030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tu powinin być losowy wynik - mozna sobie uruchomić kilka razy\n",
    "get_action(env, state, model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81f58561-8278-4e00-ae0b-331498259d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a tu predykcja sieci\n",
    "assert(get_action(env, state, model, 0) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad6a873-16bb-4965-9c90-69ee38f23a5e",
   "metadata": {},
   "source": [
    "#### 4. Aktualizacja wag modelu\n",
    "Zaimplementować funkcję aktualizującą wagi modelu:\n",
    "\n",
    "1. Wybierz batch losowych próbek z bufora\n",
    "2. Oblicz wartość $y$ ($y$ - oczekiwane wyjścia sieci, do których będziemy douczać):\n",
    "  \n",
    "    $$y_a = \\begin{cases} r & \\text{jeśli to koniec epizodu} \\\\ r + \\gamma \\max_{a'} Q(s', a') &      \\text{w przeciwnym przypadku} \\end{cases}$$\n",
    "Wskazówka: zamiast if można wykorzystać w drugim członie równania mnożenie przez (1-dones).\n",
    "\n",
    "Chcemy aktualizaować $Q(s, a)$ tylko dla akcji $a$, która faktycznie została wykonana. Nasza sieć ma dwa wyjścia (dla dwóch akcji), więc do funkcji fit zawsze musimy podawać jako $y$ macierz o rozmiarze rozmiar batcha $\\times$ liczba możliwych akcji.\n",
    "\n",
    "Aby nie aktualizować wyjscia sieci dla drugiej (niewykonanej) akcji realizujemy punkt 2 następująco:\n",
    "\n",
    "* wyliczamy wartość $y_a$ wg wzoru powyżej (wymiar rozmiar batcha)\n",
    "* wyliczmy $y$ jako predykcję sieci dla $s$ (wymiar rozmiar batcha $\\times$ liczba akcji)\n",
    "* podmieniamy wartość $y$ na $y_a$ dla akcji $a$\n",
    "* w ten sposób wartość $y$ dla niewybranej akcji jest taka sama jak predykcja sieci, więc błąd jest 0, więc nie aktualizujemy\n",
    "\n",
    "Uwaga: w tym ćwiczeniu nie korzystamy z Q-tabeli, aproksymujemy Q-wartości z wykorzystaniem sieci neuronowej.\n",
    "\n",
    "3. Zaktualizuj wagi sieci neuronowej\n",
    "\n",
    "Bufor jest listą krotek zawierających (state, action, reward, new_state, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeccdf5e-7b11-4dc2-bcb0-a35f55ebe519",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.array([[-0.005, 0.001, 0.0001, 0.0001]])\n",
    "new_state = np.array([[0.005, 0.001, 0.0001, 0.0001]])\n",
    "buffer = [(state, 0, 1, new_state, True),\n",
    "          (state, 1, 1, new_state, False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e479238b-4125-4b0b-906b-8a5b724e433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(model, buffer, batch_size):\n",
    "    # TODO jeśli rozmiar bufora jest mniejszy niż batch_size wyjdź z funkcji poprzez return\n",
    "\n",
    "    minibatch = # TODO wybierz buffer_size losowych próbek z bufora (funkcja samle z modułu random)\n",
    "\n",
    "    # wyciągamy z bufora odpowienie dane i zamieniamy na macierze numpy\n",
    "    states, actions, rewards, new_states, dones = zip(*minibatch)\n",
    "    actions, rewards, dones = np.array(actions), np.array(rewards), np.array(dones)\n",
    "    # states to krotka (o batch_size elementach) np.arrayów o rozmiarze 1 x state size (new states też)\n",
    "    states = # TODO zamień na np.array i zmień rozmiar na batch_size x state_size\n",
    "    new_states = # TODO zamień na np.array i zmień rozmiar na batch_size x state_size\n",
    "\n",
    "    y_a = # wyznać y_a według wzoru w 2\n",
    "    y = # wyznacz y jako predykcję sieci dla states\n",
    "        \n",
    "    for i, action in enumerate(actions):\n",
    "        # TODO podmień wartość y dla odpowiedniej akcji na y_a\n",
    "        \n",
    "    # ucz model przez jedną epokę, zastosuj verbose=0, aby uniknąć wydruków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2099b11c-532e-4998-96e1-86a8d92ee537",
   "metadata": {},
   "outputs": [],
   "source": [
    "update(model, buffer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedec3f-26f5-4cea-8530-186bbb6ef59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt.assert_allclose(model.layers[2].get_weights()[1], np.array([-0.08411561, -0.563301]),\n",
    "                    rtol=1e-5, atol=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7c6e5-2432-4c65-9400-d0b9ff370fb0",
   "metadata": {},
   "source": [
    "#### 5. Epizod z wykorzystaniem zachłannej polityki\n",
    "Zaimplementuj funkcję, która wykona jeden epizod, realizując politykę zachłanną (zawsze wybieramy akcję o najlepszej q-vartości) i zwróci wartość skumulowanej nagrody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf96ed82-37e8-4c55-bd15-422b920a2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval_episode(env, model):\n",
    "    state, info = env.reset()\n",
    "    state = state.reshape(1, state_size)\n",
    "    done = False\n",
    "    rewards = 0\n",
    "    for j in range(max_steps):\n",
    "        q_values = #TODO predykcja sieci dla danego stanu\n",
    "        action = #TODO wybierz najlepszą akcję\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        state = state.reshape(1, state_size)\n",
    "        done = terminated or truncated\n",
    "        # TODO aktualizacja sumy nagród\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fada48e8-d4a7-483d-897a-6dd9fbed113c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_eval_episode(env, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a25f2-18a8-421f-b9cb-001e241a541b",
   "metadata": {},
   "source": [
    "#### Algorytm uczenia\n",
    "Zaimplementuj pętlę algorymu uczenia:\n",
    "\n",
    "1. Zainicjalizuj sieć neuronową i pusty bufor próbek.\n",
    "2. Z prawdopodobieństwem $\\epsilon$ wybierz losową akcję, w przeciwnym przypadku wybierz akcję zgodnie z polityką\n",
    "3. Poprzez interakcje ze środowiskiem uzyskaj $(s, a, r, s', done)$\n",
    "4. Dodaj $(s, a, r, s', done)$ do bufora\n",
    "5. Zaktualizuj wagi sieci neuronowej\n",
    "6. Zaktualizuj $\\epsilon$ - jeśli jest większy niż epsilon_min, pomnóż przez epsilon_decay\n",
    "7. Dopóki nie warunek stopu idź do 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91e6d1-c3a7-48f9-8cfe-3d0a16529b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = []\n",
    "model = make_network()\n",
    "for i in range(200):\n",
    "    state, info = env.reset()\n",
    "    state = state.reshape(1, state_size)\n",
    "    done = False\n",
    "    rewards = 0\n",
    "    for j in range(max_steps):\n",
    "        action = # TODO wybierz akcję stosując strategię epsilon zachłanną\n",
    "        new_state, reward, terminated, truncated, info = # TODO wykonaj akcję\n",
    "        new_state = new_state.reshape(1, state_size)\n",
    "        done = terminated or truncated\n",
    "        rewards += reward\n",
    "        # na koniec zamianiamy nagrodę na -10, żeby zaznaczyć, że nie chcemy żeby wahadło spadało\n",
    "        if done:\n",
    "            reward = -10\n",
    "        # TODO dodaj uzyskaną próbkę do bufora\n",
    "        # TODO jesli długość bufora jest większa niż buffer_size usuń pierwszą próbkę (użyć  list.pop([i]))\n",
    "        state = # TODO zaktualizuj stan\n",
    "        # TODO zaktualizuj wagi modelu\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    env.close()\n",
    "    # epsilon decay\n",
    "    # TODO zaktualizuj epsilon zgodnie z 6\n",
    "    print(i, \": \", rewards)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        eval_reward = # TODO wyznacz nagrodę uzyskaną z wykorzystaniem startegii optymalnej\n",
    "        print(\"epsilon = {:.2f}\".format(epsilon), \"eval run reward = \", eval_reward)\n",
    "        if eval_reward >= 200:\n",
    "            print(\"Rozwiązane!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc0f7ac5-19cd-490e-bb8d-ec52457aaf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_vid = RecordVideo(env, video_folder=\"videos\", name_prefix=\"agent-control\", disable_logger=True)\n",
    "run_eval_episode(env_vid, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a262c-1cab-4fd0-93ca-70158778e434",
   "metadata": {},
   "source": [
    "### Pytania\n",
    "1. Jak oceniasz na podstawie przygotowanego nagrania jakość uzyskanego rozwiązania?\n",
    "2. Jeśli są jakieś problemy to jak je można poprawić?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e8e36-8c3d-45e0-aa6d-878cb7187bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
